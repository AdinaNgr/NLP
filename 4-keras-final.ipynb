{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Input, Activation, Dense, Permute, Reshape, Dropout\n",
    "from keras.layers import add, dot, multiply, concatenate\n",
    "from keras.layers import LSTM, Conv1D, TimeDistributed, Lambda\n",
    "from keras.initializers import Constant\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "\n",
    "from dataproc_utils import load_wordvecs, load_proc_data, make_word_freq_V, word2idx, vocab_vectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 25\n",
    "random_state = 42\n",
    "n_pars = 9 # max number of paragraphs from each document\n",
    "par_size = 15  # max paragraph length (num of words in each paragraph)\n",
    "claim_size = 15  # max num of words in each claim\n",
    "embedding_dim = 25  # should be 100\n",
    "output_size = 4  # size of the output vector, corresponds to the number of classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings from Glove\n",
    "\n",
    "Only the words we use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17355 pretrained embeddings\n"
     ]
    }
   ],
   "source": [
    "# open saved wordvecs from file\n",
    "w2v = load_wordvecs('twitter_glo_vecs\\\\wordvecs25d.txt')\n",
    "print(len(w2v), 'pretrained embeddings')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessed data\n",
    "\n",
    "- document per line\n",
    "- claim per line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data and labels\n",
    "data = load_proc_data('processed_data\\\\train_bodies.txt', 'processed_data\\\\train_claims.txt', split_pars=True)\n",
    "labels = [label for body, claim, label in data]\n",
    "y = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of similarity matrix train p_tfidf: (49972, 9)\n"
     ]
    }
   ],
   "source": [
    "# initialize tfidf tokenizer\n",
    "# fit on concatenated list of bodies and claims\n",
    "# and transform bodies/pars and claims at the same time\n",
    "# measure cosine similarity btw tfidf representations of bodies & claims to compute p_tfidf (claim-evidence sim vector)\n",
    "# tfidf_body shape (len(claims), n_pars, vocab size)\n",
    "# tfidf_claim shape (len(claims), vocab size)\n",
    "# p_tfidf output shape: (len(claims), n_pars)\n",
    "\n",
    "# load pre-computed p_tfidf similarity matrix for train data\n",
    "p_tfidf = np.loadtxt('processed_data\\\\p_tfidf_train.txt', dtype=np.float32)\n",
    "print('Shape of similarity matrix train p_tfidf:', p_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF\n",
    "\n",
    "Tfidf computed for every claim. Each claim is matched to one document (9 paragraphs). NOTE: Claims might repeat, but with new document as reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/validation split\n",
    "train_data, val_data, train_p_tfidf, val_p_tfidf, train_labels, val_labels = train_test_split(data, p_tfidf, y,\n",
    "                                                                                              test_size=.2,\n",
    "                                                                                              random_state=random_state)\n",
    "# print('First input tuple (body, claim, stance):\\n', train_data[0])\n",
    "# print('First input p_tfidf:\\n', train_p_tfidf[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 16908 unique words in the train set which have glove embeddings\n"
     ]
    }
   ],
   "source": [
    "# create a vocabulary dict from train data (we exclude rare words, which appear only once)\n",
    "word2freq = make_word_freq_V(train_data, fmin=2)\n",
    "word2index = word2idx(word2freq, pretrained=w2v)\n",
    "vocab_size = len(word2index)\n",
    "print('Vocab size:', vocab_size, 'unique words in the train set which have glove embeddings')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize input words (turn each word into its index from the word2index dict)\n",
    "# for new words in test set that don't appear in train set, use index of <unknown>\n",
    "train_body, train_claim = vocab_vectorizer(train_data, word2index, max_par_len=par_size, max_claim_len=claim_size)\n",
    "val_body, val_claim = vocab_vectorizer(val_data, word2index, max_par_len=par_size, max_claim_len=claim_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare embedding matrix\n",
    "embedding_matrix = np.zeros((vocab_size + 1, embedding_dim))\n",
    "for w, i in word2index.items():\n",
    "    embedding_matrix[i] = w2v[w]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained word vectors into embedding layers\n",
    "# we set trainable to false to keep the embeddings fixed\n",
    "embedding_body = Embedding(vocab_size + 1,\n",
    "                            embedding_dim,\n",
    "                            embeddings_initializer=Constant(embedding_matrix),\n",
    "                            input_length=(n_pars, par_size,),\n",
    "                            trainable=False)\n",
    "\n",
    "embedding_claim = Embedding(vocab_size + 1,\n",
    "                            embedding_dim,\n",
    "                            embeddings_initializer=Constant(embedding_matrix),\n",
    "                            input_length=claim_size,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input body (?, 9, 15)\n",
      "input claim (?, 15)\n",
      "input p_tfidf (?, 9)\n"
     ]
    }
   ],
   "source": [
    "# initialize input placeholders and embed pre-trained word vectors\n",
    "input_body = Input(shape=(n_pars, par_size,), dtype='int32')\n",
    "input_claim = Input(shape=(claim_size,), dtype='int32')\n",
    "input_p_tfidf = Input(shape=(n_pars,), dtype='float32')\n",
    "\n",
    "print('input body', input_body.shape)     # (?, 9, 15)\n",
    "print('input claim', input_claim.shape)    # (?, 15)\n",
    "print('input p_tfidf', input_p_tfidf.shape)  # (?, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedded body (?, 9, 15, 25)\n",
      "embedded claim (?, 15, 25)\n"
     ]
    }
   ],
   "source": [
    "embedded_body = embedding_body(input_body)\n",
    "embedded_claim = embedding_claim(input_claim)\n",
    "\n",
    "print('embedded body', embedded_body.shape)   # (?, 9, 15, 25)\n",
    "print('embedded claim', embedded_claim.shape)  # (?, 15, 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train two 1D convnets (should be time distributed with maxout layer)\n",
    "cnn_body = TimeDistributed(Conv1D(100, 5, padding='valid', activation='relu'))(embedded_body)\n",
    "cnn_body = Lambda(lambda x: K.max(x, axis=-1, keepdims=False))(cnn_body)  # this should be maxout\n",
    "#cnn_body = Lambda(lambda x: tf.contrib.layers.maxout(x, num_units=1))(cnn_body) ## does not work for some reason!!?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_claim = Conv1D(100, 5, padding='valid', activation='relu')(embedded_claim)\n",
    "cnn_claim = Lambda(lambda x: K.max(x, axis=-1, keepdims=False))(cnn_claim)  # this should be maxout\n",
    "#cnn_claim = Lambda(lambda x: tf.contrib.layers.maxout(x, num_units=1))(cnn_claim) ## does not work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Maxout, we take the maximum value of the 100 values in the vector extracted by the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn_body shape (?, 9, 11)\n",
      "cnn_claim shape (?, 11)\n"
     ]
    }
   ],
   "source": [
    "# maxout eliminates the last dimension from the cnn representations:\n",
    "# converts cnn_body with shape (?, 9, 11, 100) to (?, 9, 11)\n",
    "# and cnn_claim with shape (?, 11, 100) to (?, 11)\n",
    "print('cnn_body shape', cnn_body.shape)  # (?, 9, 11)\n",
    "print('cnn_claim shape', cnn_claim.shape)  # (?, 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTMs\n",
    "\n",
    "- TimeDistributed for documents\n",
    "- simple for claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm body (?, 9, 100)\n",
      "lstm claim (?, 100)\n"
     ]
    }
   ],
   "source": [
    "# train two lstms\n",
    "lstm_body = TimeDistributed(LSTM(100))(embedded_body)\n",
    "lstm_claim = (LSTM(100))(embedded_claim)\n",
    "\n",
    "print('lstm body', lstm_body.shape) # (?, 9, 100)\n",
    "print('lstm claim', lstm_claim.shape) # (?, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why? \\/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm_body * p_tfidf (?, 9, 100)\n",
      "lstm_claim (?, 100)\n"
     ]
    }
   ],
   "source": [
    "# reshape tfidf sim matrix layer from (?, 9) into (?, 9, 1)\n",
    "reshaped_p_tfidf = Reshape((n_pars, 1))(input_p_tfidf)\n",
    "lstm_body = multiply([lstm_body, reshaped_p_tfidf])\n",
    "### tensor shapes: (samples, n_pars, 100) * (samples, n_pars, 1) => (?, 9, 100)\n",
    "print('lstm_body * p_tfidf', lstm_body.shape)  # (?, 9, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_lstm (?, 9)\n"
     ]
    }
   ],
   "source": [
    "## p_lstm = lstm_claim.T x M x lstm_body[j]  a.k.a. wtf is M?\n",
    "## if normalize=True, then the output of the dot product is the cosine similarity between the two samples\n",
    "p_lstm = dot([lstm_body, lstm_claim], axes=(2, 1), normalize=True)\n",
    "print('p_lstm', p_lstm.shape)  # (samples, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "### cnn_body = cnn_body * p_lstm\n",
    "# reshape sim matrix layer from (?, 9) into (?, 9, 1)\n",
    "p_lstm = Reshape((n_pars, 1))(p_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_lstm (?, 9, 1)\n"
     ]
    }
   ],
   "source": [
    "print('p_lstm', p_lstm.shape)  # (samples, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn_body * p_lstm (?, 9, 11)\n",
      "cnn_claim (?, 11)\n"
     ]
    }
   ],
   "source": [
    "cnn_body = multiply([cnn_body, p_lstm])\n",
    "print('cnn_body * p_lstm', cnn_body.shape) # (?, 9, 11)\n",
    "print('cnn_claim', cnn_claim.shape)        # (?, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_cnn (?, 9)\n"
     ]
    }
   ],
   "source": [
    "## p_cnn = cnn_claim.T x M' x cnn_body[j]  a.k.a. wtf is M'?\n",
    "## if normalize=True, then the output of the dot product is the cosine similarity between the two samples\n",
    "p_cnn = dot([cnn_body, cnn_claim], axes=(2, 1), normalize=True)\n",
    "print('p_cnn', p_cnn.shape)  # (?, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean cnn body (?, 9)\n"
     ]
    }
   ],
   "source": [
    "# no clue whats going from here onward\n",
    "## o = [mean(cnn_body); [max(p_cnn); mean(p_cnn)]; [max(p_lstm); mean(p_lstm)]; [max(p_tfidf); mean(p_tfidf)]]\n",
    "mean_cnn_body = Lambda(lambda x: K.mean(x, axis=2))(cnn_body)\n",
    "print('mean cnn body', mean_cnn_body.shape)  # (?, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking mean and max similarities\n",
    "max_p_cnn = Lambda(lambda x: K.max(x, axis=1))(p_cnn)\n",
    "mean_p_cnn = Lambda(lambda x: K.mean(x, axis=1))(p_cnn)\n",
    "max_p_lstm = Lambda(lambda x: K.max(x, axis=1))(p_lstm)\n",
    "mean_p_lstm = Lambda(lambda x: K.mean(x, axis=1))(p_lstm)\n",
    "max_p_tfidf = Lambda(lambda x: K.max(x, axis=1))(reshaped_p_tfidf)\n",
    "mean_p_tfidf = Lambda(lambda x: K.mean(x, axis=1))(reshaped_p_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape some layers to make their dimensions compatible\n",
    "max_p_cnn = Reshape((1,))(max_p_cnn)\n",
    "mean_p_cnn = Reshape((1,))(mean_p_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output (?, 15)\n"
     ]
    }
   ],
   "source": [
    "output = concatenate([mean_cnn_body,\n",
    "                      max_p_cnn, mean_p_cnn,\n",
    "                      max_p_lstm, mean_p_lstm,\n",
    "                      max_p_tfidf, mean_p_tfidf])\n",
    "\n",
    "print('output', output.shape)  # (?, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response layer: (?, 126)\n"
     ]
    }
   ],
   "source": [
    "response = concatenate([output, lstm_claim, cnn_claim])\n",
    "print('response layer:', response.shape)   # (?, 126)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# home stretch\n",
    "stance = Dense(300, activation='relu')(response)\n",
    "stance = Dropout(0.3)(stance)\n",
    "preds = Dense(output_size, activation='softmax')(stance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model\n",
    "model = Model([input_body, input_claim, input_p_tfidf], preds)\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 9, 15)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 9, 15, 25)    422725      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 9)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 15)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 9, 100)       50400       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 9, 1)         0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 15, 25)       422725      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 9, 100)       0           time_distributed_2[0][0]         \n",
      "                                                                 reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 100)          50400       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 9, 11, 100)   12600       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 9)            0           multiply_1[0][0]                 \n",
      "                                                                 lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 9, 11)        0           time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 9, 1)         0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 11, 100)      12600       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 9, 11)        0           lambda_1[0][0]                   \n",
      "                                                                 reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 11)           0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dot_2 (Dot)                     (None, 9)            0           multiply_2[0][0]                 \n",
      "                                                                 lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None,)              0           dot_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None,)              0           dot_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 9)            0           multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 1)            0           lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 1)            0           lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 1)            0           reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 1)            0           reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 1)            0           reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 1)            0           reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 15)           0           lambda_3[0][0]                   \n",
      "                                                                 reshape_3[0][0]                  \n",
      "                                                                 reshape_4[0][0]                  \n",
      "                                                                 lambda_6[0][0]                   \n",
      "                                                                 lambda_7[0][0]                   \n",
      "                                                                 lambda_8[0][0]                   \n",
      "                                                                 lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 126)          0           concatenate_1[0][0]              \n",
      "                                                                 lstm_2[0][0]                     \n",
      "                                                                 lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 300)          38100       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 300)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 4)            1204        dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,010,754\n",
      "Trainable params: 165,304\n",
      "Non-trainable params: 845,450\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# print model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 39977 samples, validate on 9995 samples\n",
      "Epoch 1/25\n",
      "39977/39977 [==============================] - 41s 1ms/step - loss: 0.7406 - acc: 0.7353 - val_loss: 0.6787 - val_acc: 0.7465\n",
      "Epoch 2/25\n",
      "39977/39977 [==============================] - 35s 879us/step - loss: 0.6160 - acc: 0.7653 - val_loss: 0.5938 - val_acc: 0.7799\n",
      "Epoch 3/25\n",
      "39977/39977 [==============================] - 36s 888us/step - loss: 0.5298 - acc: 0.7976 - val_loss: 0.5281 - val_acc: 0.7993\n",
      "Epoch 4/25\n",
      "39977/39977 [==============================] - 35s 868us/step - loss: 0.4653 - acc: 0.8196 - val_loss: 0.4772 - val_acc: 0.8162\n",
      "Epoch 5/25\n",
      "39977/39977 [==============================] - 35s 868us/step - loss: 0.4187 - acc: 0.8394 - val_loss: 0.4760 - val_acc: 0.8153\n",
      "Epoch 6/25\n",
      "39977/39977 [==============================] - 35s 872us/step - loss: 0.3806 - acc: 0.8536 - val_loss: 0.4464 - val_acc: 0.8410\n",
      "Epoch 7/25\n",
      "39977/39977 [==============================] - 35s 879us/step - loss: 0.3508 - acc: 0.8639 - val_loss: 0.4504 - val_acc: 0.8378\n",
      "Epoch 8/25\n",
      "39977/39977 [==============================] - 35s 880us/step - loss: 0.3261 - acc: 0.8725 - val_loss: 0.4322 - val_acc: 0.8449\n",
      "Epoch 9/25\n",
      "39977/39977 [==============================] - 35s 879us/step - loss: 0.3076 - acc: 0.8803 - val_loss: 0.4607 - val_acc: 0.8430\n",
      "Epoch 10/25\n",
      "39977/39977 [==============================] - 35s 881us/step - loss: 0.2938 - acc: 0.8838 - val_loss: 0.4371 - val_acc: 0.8475\n",
      "Epoch 11/25\n",
      "39977/39977 [==============================] - 35s 887us/step - loss: 0.2793 - acc: 0.8894 - val_loss: 0.4438 - val_acc: 0.8486\n",
      "Epoch 12/25\n",
      "39977/39977 [==============================] - 36s 892us/step - loss: 0.2665 - acc: 0.8950 - val_loss: 0.4415 - val_acc: 0.8574\n",
      "Epoch 13/25\n",
      "39977/39977 [==============================] - 36s 896us/step - loss: 0.2569 - acc: 0.8999 - val_loss: 0.4438 - val_acc: 0.8613\n",
      "Epoch 14/25\n",
      "39977/39977 [==============================] - 36s 897us/step - loss: 0.2527 - acc: 0.9027 - val_loss: 0.4224 - val_acc: 0.8631\n",
      "Epoch 15/25\n",
      "39977/39977 [==============================] - 36s 899us/step - loss: 0.2457 - acc: 0.9031 - val_loss: 0.4510 - val_acc: 0.8647\n",
      "Epoch 16/25\n",
      "39977/39977 [==============================] - 36s 896us/step - loss: 0.2374 - acc: 0.9073 - val_loss: 0.4657 - val_acc: 0.8645\n",
      "Epoch 17/25\n",
      "39977/39977 [==============================] - 36s 902us/step - loss: 0.2310 - acc: 0.9087 - val_loss: 0.4544 - val_acc: 0.8597\n",
      "Epoch 18/25\n",
      "39977/39977 [==============================] - 36s 900us/step - loss: 0.2274 - acc: 0.9107 - val_loss: 0.4728 - val_acc: 0.8676\n",
      "Epoch 19/25\n",
      "39977/39977 [==============================] - 36s 900us/step - loss: 0.2242 - acc: 0.9112 - val_loss: 0.4968 - val_acc: 0.8550\n",
      "Epoch 20/25\n",
      "39977/39977 [==============================] - 36s 901us/step - loss: 0.2206 - acc: 0.9135 - val_loss: 0.4899 - val_acc: 0.8632\n",
      "Epoch 21/25\n",
      "39977/39977 [==============================] - 36s 903us/step - loss: 0.2128 - acc: 0.9153 - val_loss: 0.5398 - val_acc: 0.8591\n",
      "Epoch 22/25\n",
      "39977/39977 [==============================] - 36s 901us/step - loss: 0.2128 - acc: 0.9178 - val_loss: 0.5512 - val_acc: 0.8690\n",
      "Epoch 23/25\n",
      "39977/39977 [==============================] - 36s 902us/step - loss: 0.2136 - acc: 0.9178 - val_loss: 0.5366 - val_acc: 0.8645\n",
      "Epoch 24/25\n",
      "39977/39977 [==============================] - 36s 910us/step - loss: 0.2089 - acc: 0.9173 - val_loss: 0.5057 - val_acc: 0.8682\n",
      "Epoch 25/25\n",
      "39977/39977 [==============================] - 36s 908us/step - loss: 0.2053 - acc: 0.9176 - val_loss: 0.5473 - val_acc: 0.8696\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20d4aed14e0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "model.fit([train_body, train_claim, train_p_tfidf], train_labels,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=([val_body, val_claim, val_p_tfidf], val_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
